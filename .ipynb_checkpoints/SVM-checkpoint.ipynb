{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SVM\n",
    "Support Vector Machine (SVM) is a relatively simple Supervised Machine Learning Algorithm used for classification and/or regression. It is more preferred for classification but is sometimes very useful for regression as well. Basically, SVM finds a hyper-plane that creates a boundary between the types of data. In 2-dimensional space, this hyper-plane is nothing but a line. In SVM, we plot each data item in the dataset in an N-dimensional space, where N is the number of features/attributes in the data. Next, find the optimal hyperplane to separate the data. So by this, you must have understood that inherently, SVM can only perform binary classification (i.e., choose between two classes). However, there are various techniques to use for multi-class problems"
   ],
   "metadata": {
    "id": "QAGtknNQ29Zj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qw888-V2reA"
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, lr = 0.001, λ = 0.01,n = 1000):\n",
    "        self.lr = lr\n",
    "        self.λ = λ\n",
    "        self.n = n\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def predict(self, X,):\n",
    "        return np.sign(np.dot(X, self.w) - self.b)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.where(y <= 0,-1,1)\n",
    "        n_samples,n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.n):\n",
    "            for idx,xi in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(xi,self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2*self.λ*self.w)\n",
    "                else :\n",
    "                    self.w -= self.lr * (2*self.λ*self.w - np.dot(xi,y_[idx]))\n",
    "\n"
   ]
  }
 ]
}
